name: Airflow + Flake8 + Tests

on:
  push:
    branches:
      - main
      - 'test*'
  pull_request:
    branches:
      - main

jobs:
  lint-and-test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_USER: airflow
          POSTGRES_PASSWORD: airflow
          POSTGRES_DB: airflow
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U airflow"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=5

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python environment
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f api/requirements.txt ]; then
            pip install -r api/requirements.txt
          else
            # Fallback to basic Airflow installation if requirements file doesn't exist
            pip install apache-airflow pytest flake8
          fi

      - name: List working directory contents
        run: |
          echo "Current directory: $(pwd)"
          echo "Directory contents:"
          ls -la

      - name: Create required directories
        run: |
          mkdir -p dags tests scripts data processed
          # Make sure scripts are executable
          if [ -d scripts ]; then
            chmod +x scripts/*.py || echo "No scripts to make executable yet"
          fi

      - name: Run Flake8 linting
        run: flake8 dags scripts tests --max-line-length=79 --ignore=E203,W503 || echo "Linting issues found but continuing"

      # Create a docker compose configuration specifically for testing
      - name: Create Docker Compose test configuration
        run: |
          echo "Creating docker-compose-test.yml file..."
          cat > docker-compose-test.yml <<EOL
          services:
            postgres:
              image: postgres:13
              environment:
                POSTGRES_USER: airflow
                POSTGRES_PASSWORD: airflow
                POSTGRES_DB: airflow
              healthcheck:
                test: ["CMD", "pg_isready", "-U", "airflow"]
                interval: 5s
                retries: 5

            airflow:
              image: apache/airflow:2.7.1
              command: standalone
              depends_on:
                - postgres
              volumes:
                - ./dags:/opt/airflow/dags
                - ./tests:/opt/airflow/tests
                - ./scripts:/opt/airflow/scripts
                - ./data:/opt/airflow/data
                - ./processed:/opt/airflow/processed
              environment:
                - AIRFLOW__CORE__EXECUTOR=LocalExecutor
                - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
                - AIRFLOW__CORE__LOAD_EXAMPLES=False
                - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
                - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
                - AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=False
                - AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=30
                - AIRFLOW__CORE__LOGGING_LEVEL=INFO
          EOL
          echo "Docker compose file created. Contents:"
          cat docker-compose-test.yml

      - name: Verify Docker installation
        run: |
          docker --version
          docker compose version

      - name: Start Docker Compose
        run: |
          echo "Starting Docker Compose services..."
          docker compose -f docker-compose-test.yml up -d
          echo "Docker services started"
          docker ps -a

      - name: Wait for services to be ready
        run: |
          echo "Waiting for Airflow to be ready..."
          sleep 30  # Initial wait for containers to start
          max_attempts=15
          attempt=1
          while [ $attempt -le $max_attempts ]; do
            echo "Attempt $attempt/$max_attempts: Checking if Airflow is ready..."
            if docker compose -f docker-compose-test.yml exec -T airflow airflow db check > /dev/null 2>&1; then
              echo "Airflow is ready!"
              break
            fi
            echo "Airflow is not ready yet. Waiting..."
            sleep 10
            attempt=$((attempt+1))
          done

          if [ $attempt -gt $max_attempts ]; then
            echo "Airflow failed to become ready in time. Check logs."
            docker compose -f docker-compose-test.yml logs airflow
            exit 1
          fi

      - name: Initialize Airflow
        run: |
          echo "Initializing Airflow..."
          docker compose -f docker-compose-test.yml exec -T airflow airflow db init
          docker compose -f docker-compose-test.yml exec -T airflow airflow users create \
            -r Admin -u admin -p admin -e admin@example.com -f admin -l admin

          echo "Creating pool for stock data tasks..."
          docker compose -f docker-compose-test.yml exec -T airflow airflow pools set stock_data_pool 5 "Pool for stock data tasks"

          # Make scripts executable inside the container
          docker compose -f docker-compose-test.yml exec -T airflow bash -c "
            chmod +x /opt/airflow/scripts/*.py || echo 'No scripts to chmod'
          "

      - name: Run tests
        run: |
          echo "Running tests..."
          docker compose -f docker-compose-test.yml exec -T airflow pytest tests/test_data_collection_dag.py -v

      - name: Show Airflow logs in case of failure
        if: failure()
        run: |
          echo "Showing logs due to failure..."
          echo "Airflow Container Logs:"
          docker compose -f docker-compose-test.yml logs airflow
          echo "DAGs Directory Contents:"
          docker compose -f docker-compose-test.yml exec -T airflow ls -la /opt/airflow/dags || echo "Failed to list DAGs directory"
          echo "Scripts Directory Contents:"
          docker compose -f docker-compose-test.yml exec -T airflow ls -la /opt/airflow/scripts || echo "Failed to list scripts directory"

      - name: Shutdown Docker Compose
        if: always()
        run: |
          echo "Shutting down Docker Compose services..."
          docker compose -f docker-compose-test.yml down
